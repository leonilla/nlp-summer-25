{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWZUOvpuU3no"
      },
      "source": [
        "## Introduction to Natural Language Processing\n",
        "[**CC-BY-NC-SA**](https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en)<br/>\n",
        "Prof. Dr. Annemarie Friedrich<br/>\n",
        "Faculty of Applied Computer Science, University of Augsburg<br/>\n",
        "Date: **SS 2025**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g2mkm10VBiq"
      },
      "source": [
        "# Linguistic Background (Homework)\n",
        "\n",
        "## Mandatory Reading\n",
        "\n",
        "Adam Poliak. [A Survey on Recognizing Textual Entailment as an NLP Evaluation.](https://aclanthology.org/2020.eval4nlp-1.10.pdf) Eval4NLP Workshop. 2020.\n",
        "\n",
        "**Reading Instructions:**\n",
        "\n",
        "* Read pages 1-6 of the survey article.\n",
        "* Look up terms that you do not know, but do not worry too much if you do not understand everything yet. Try to get the gist (the main points) of the article.\n",
        "* Spend at most 1 hour on this task.\n",
        "\n",
        "## Coding Practice\n",
        "\n",
        "In this homework, we will explore an NLP dataset for *Recognizing Textual Entailment* RTE using the [HuggingFace Datasets](https://huggingface.co/datasets) repository.\n",
        "\n",
        "We will work with the training dataset of RTE as provided by the [SuperGLUE](https://arxiv.org/abs/1905.00537) benchmark. The RTE data has been created within the context of several challenges (shared task) that took place from 2006-2009. The original data has three labels: `entailment`, `neutral`, and `contradiction`. The SuperGLUE version of the dataset simplifies this to the two labels `entailment` and `no_entailment` by merging the latter two labels.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7qolosgU4hN"
      },
      "outputs": [],
      "source": [
        "# Install the frameword and load the dataset (training split)\n",
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "rte = load_dataset(\"super_glue\", \"rte\", split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icmgB4TgXFeB"
      },
      "outputs": [],
      "source": [
        "# Let's take a look at this dataset object.\n",
        "print(rte)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEGmwoFYY4HB"
      },
      "source": [
        "**Understanding the API**\n",
        "\n",
        "HuggingFace Dataset objects are described [here](https://huggingface.co/docs/datasets/v1.7.0/exploring.html). Take a brief look at the API article to understand how you can access rows and columns, and the values within rows, from the `rte Dataset` object. (No need to worry about the other functions of `Dataset` at the moment.)\n",
        "\n",
        "**Exercise: Negation Detection**\n",
        "\n",
        "The goal of this exercise is to investigate whether the RTE dataset contains a bias with regard to negation, i.e., will simply checking if an instance contains a negation tell us already something about the likelihood of the two labels `entailment` vs. `no_entailment`?\n",
        "\n",
        "\n",
        "We will simplify the task of negation detection a bit and pay attention only to the following negation markers (taken from [here](https://www.english-efl.com/lessons/negation-in-english/) - you can find a more comprehensive description of negation in English on this web site, too!):\n",
        "\n",
        "> In standard English, negative clauses and sentences commonly include the negative particle not or the contracted negative n't. Other negative words include no, none, nothing, nobody, nowhere, and never.\n",
        "\n",
        "For comparability of results, please use the NLTK implementation of the Punkt tokenization algorithm for sentence segmentation and word tokenization.\n",
        "For each of the two labels, count (a) how often the premise contains a negation, and (b) how often the hypothesis contains a negation. Normalize these counts, i.e., compute the percentage of total instances labeled with the label of interest.\n",
        "\n",
        "For your implementation, use built-in Python functions, `numpy` and `defaultdict`.\n",
        "\n",
        "‚ùìIf we observe a negated premise/hypothesis, can we make a better guess whether the instance is likely to be labeled with `entailment` or `no entailment`?\n",
        "\n",
        "**Optional**: Implement the solution additionally using the `pandas` and `numpy` toolkits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhBpzZeXQeVD"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
